{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "be60dbd3",
      "metadata": {
        "id": "be60dbd3"
      },
      "source": [
        "# Session 0: Orientation and setup. LLMs for low-resource languages\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**üìö Course Repository:** [github.com/NinaKivanani/Tutorials_low-resource-llm](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NinaKivanani/Tutorials_low-resource-llm/blob/main/Session0_Orientation_and_Setup_LLMs_Low_Resource.ipynb)\n",
        "[![GitHub](https://img.shields.io/badge/GitHub-View%20Repository-blue?logo=github)](https://github.com/NinaKivanani/Tutorials_low-resource-llm)\n",
        "[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "## Your Learning Quest Begins Here!\n",
        "\n",
        "**Welcome, Language Champion!** üëã You're about to embark on a journey that will transform you from an AI curious learner into a **multilingual AI expert**. This isn't just another coding tutorial‚Äîit's your mission to democratize AI for the world's 6,900+ languages!\n",
        "\n",
        "### üèÜ Your 30-Minute Setup Challenge:\n",
        "```\n",
        "üéØ Mission Checklist:\n",
        "‚îú‚îÄ‚îÄ üîß Power Up Your Environment     [‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 0%\n",
        "‚îú‚îÄ‚îÄ üåç Choose Your Language Quest    [‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 0%  \n",
        "‚îú‚îÄ‚îÄ üìä Build Your Evaluation Toolkit [‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 0%\n",
        "‚îú‚îÄ‚îÄ ü§ñ Test with Real AI Models      [‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 0%\n",
        "‚îî‚îÄ‚îÄ üöÄ Ready for Session 1!         [‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°] 0%\n",
        "```\n",
        "\n",
        "**‚è±Ô∏è Total time:** 30-45 minutes of pure setup magic!  \n",
        "\n",
        "---\n",
        "\n",
        "## üåü The Big Picture: Why this session matters\n",
        "\n",
        "**üö® The Problem:\n",
        "\n",
        "Current LLMs are strongest in English and a small number of high-resource languages. For most of the world‚Äôs languages, data coverage, tools, and evaluation resources are limited.  \n",
        "\n",
        "This session helps you:\n",
        "\n",
        "- make sure your technical setup will not block you in later sessions  \n",
        "- prepare language-specific examples that you will re-use across the course  \n",
        "- think from the beginning about correctness, fluency, cultural fit, and safety in low-resource settings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c474afb1",
      "metadata": {
        "id": "c474afb1"
      },
      "source": [
        "## üó∫Ô∏è Tutorial roadmap. where Session 0 fits\n",
        "\n",
        "### The full tutorial is organized as follows.\n",
        "\n",
        "**üîç Session 0. Orientation and setup**  \n",
        "- Environment, language choice, and evaluation sheet preparation.\n",
        "**üîç Session 1: Intro to LLM: Dialogue summarization in low-resource settings**\n",
        "- How LLMs handle multilingual dialogue, tokenization effects, and simple evaluation.\n",
        "\n",
        "**üéØ Session 2: Prompt design and cross-lingual prompting**\n",
        "- Designing prompts that work across languages, with a focus on low-resource ones.\n",
        "\n",
        "**‚öôÔ∏è Session 3: Lightweight model adaptation**\n",
        "- Fine-tuning or parameter-efficient adaptation for specific domains or languages.\n",
        "\n",
        "**‚öñÔ∏è Session 4: Bias, safety, and evaluation**\n",
        "- Identifying and documenting biases and failure patterns, especially for under-represented communities.\n",
        "\n",
        "This notebook only aims to ensure that, by the time you start Session 1, your environment and data are ready."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9082f776",
      "metadata": {
        "id": "9082f776"
      },
      "source": [
        "## ‚úÖ Step 0: Quick Start Checklist\n",
        "Before you proceed, check the following.\n",
        "\n",
        "**üîß Environment**\n",
        "- [ ] You can run a notebook in **Google Colab** or a **local Jupyter** installation  \n",
        "- [ ] You know how to run cells from top to bottom  \n",
        "- [ ] Optional. You have access to a GPU runtime in Colab or locally\n",
        "\n",
        "\n",
        "**üåç Language choice**\n",
        "- [ ] You have chosen at least one target language (for example Luxembourgish, Irish, Welsh, Maltese, Basque, etc.)  \n",
        "- [ ] You can provide 5‚Äì10 short example sentences in this language  \n",
        "- [ ] The sentences contain no personal or sensitive data\n",
        "\n",
        "**üîë Accounts (optional but useful)**\n",
        "- [ ] [Hugging Face account](https://huggingface.co) (free model access)\n",
        "- [ ] [GitHub account](https://github.com) (save your work)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a95cf03",
      "metadata": {
        "id": "0a95cf03"
      },
      "source": [
        "---\n",
        "\n",
        "## üéÆ Notebook Survival Guide\n",
        "\n",
        "### üîÑ Essential Habits (To avoid unnecessary debugging later, follow these practices.)\n",
        "- **Run cells top-to-bottom** when starting fresh\n",
        "- **Restart runtime if weird errors appear** : If you get unexpected import or CUDA errors, **restart the runtime** and re-run from the top  \n",
        "    - Colab. `Runtime ‚Üí Restart runtime`\n",
        "- **Save frequently** (Ctrl+S / Cmd+S):\n",
        "  - Colab. saves automatically, but you can also download a copy  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b040d5fe",
      "metadata": {
        "id": "b040d5fe"
      },
      "source": [
        "## üîß Step 1. Choose your execution platform\n",
        "\n",
        "You can run this notebook in any recent Jupyter environment. The most common options are.\n",
        "\n",
        "```\n",
        "ü•á Google Colab (Recommended)\n",
        "   ‚îú‚îÄ‚îÄ ‚úÖ Zero setup required\n",
        "   ‚îú‚îÄ‚îÄ ‚úÖ Free GPU power\n",
        "   ‚îú‚îÄ‚îÄ ‚úÖ Works everywhere\n",
        "   ‚îî‚îÄ‚îÄ üéÆ Click \"Open in Colab\" above!\n",
        "\n",
        "ü•à Local Jupyter  \n",
        "   ‚îú‚îÄ‚îÄ ‚úÖ Full control over the Python environment\n",
        "   ‚îú‚îÄ‚îÄ ‚úÖ Works offline\n",
        "   ‚îú‚îÄ‚îÄ ‚ö†Ô∏è  Requires Python 3.8+\n",
        "   ‚îî‚îÄ‚îÄ üéÆ Install packages below\n",
        "```\n",
        "\n",
        "In all cases, the next cell installs the Python libraries used in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8b14e214",
      "metadata": {
        "id": "8b14e214",
        "outputId": "37d4605c-19b8-4704-8a11-78695869c90a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Installing AI libraries (2-3 minutes)...\n",
            "‚úÖ Installation complete! (Dependency warnings are normal in Colab)\n"
          ]
        }
      ],
      "source": [
        "# üöÄ Installing Essential AI Libraries\n",
        "#\n",
        "# What we're installing and why:\n",
        "# ‚Ä¢ transformers: Access to pre-trained language models (BERT, GPT, etc.)\n",
        "# ‚Ä¢ datasets: Loading multilingual datasets from Hugging Face\n",
        "# ‚Ä¢ sentencepiece & tokenizers: Breaking text into pieces AI can understand\n",
        "# ‚Ä¢ accelerate: Makes models run faster\n",
        "# ‚Ä¢ sentence-transformers: Converting sentences to numbers for comparison\n",
        "# ‚Ä¢ scikit-learn: Machine learning tools for evaluation\n",
        "\n",
        "print(\"ü§ñ Installing AI libraries (2-3 minutes)...\")\n",
        "!pip -q install transformers datasets sentencepiece tokenizers accelerate sentence-transformers scikit-learn\n",
        "print(\"‚úÖ Installation complete! (Dependency warnings are normal in Colab)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba6e81d",
      "metadata": {
        "id": "fba6e81d"
      },
      "source": [
        "## üîç Step 3: System Diagnostics & Power Check!\n",
        "We will.\n",
        "\n",
        "- print versions of the main libraries  \n",
        "- check whether a GPU is available  \n",
        "- confirm that basic plotting tools work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cf1bdc1d",
      "metadata": {
        "id": "cf1bdc1d",
        "outputId": "c04fc455-3978-4e51-dfba-2643a0fb3290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéÆ SYSTEM CHECK - 2026-01-21 05:11 UTC\n",
            "üêç Python: 3.12.12 | üíª Platform: Linux\n",
            "\n",
            "üìö Library Status:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-407898090.py:15: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  print(f\"üéÆ SYSTEM CHECK - {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚úÖ Transformers: 4.57.3\n",
            "  ‚úÖ Datasets: 4.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚úÖ Sentence Transformers: 5.2.0\n",
            "  ‚úÖ PyTorch: 2.9.0+cpu\n",
            "  ‚úÖ Scikit-learn: 1.6.1\n",
            "  ‚úÖ Matplotlib: 3.10.0\n",
            "  ‚úÖ Pandas: 2.2.2\n",
            "  ‚úÖ NumPy: 2.0.2\n",
            "\n",
            "All should show ‚úÖ - if you see ‚ùå, re-run installation above!\n"
          ]
        }
      ],
      "source": [
        "# üîç Verifying Your Setup\n",
        "#\n",
        "# This cell checks that all libraries installed correctly and shows your system info.\n",
        "# If you see any ‚ùå, re-run the installation cell above.\n",
        "\n",
        "import sys, platform, importlib\n",
        "from datetime import datetime\n",
        "\n",
        "def get_version(name: str) -> str:\n",
        "    try:\n",
        "        return importlib.import_module(name).__version__\n",
        "    except:\n",
        "        return \"‚ùå not available\"\n",
        "\n",
        "print(f\"üéÆ SYSTEM CHECK - {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]} | üíª Platform: {platform.system()}\")\n",
        "print()\n",
        "\n",
        "# Check essential libraries\n",
        "libraries = [\n",
        "    (\"transformers\", \"Transformers\"), (\"datasets\", \"Datasets\"),\n",
        "    (\"sentence_transformers\", \"Sentence Transformers\"), (\"torch\", \"PyTorch\"),\n",
        "    (\"sklearn\", \"Scikit-learn\"), (\"matplotlib\", \"Matplotlib\"),\n",
        "    (\"pandas\", \"Pandas\"), (\"numpy\", \"NumPy\")\n",
        "]\n",
        "\n",
        "print(\"üìö Library Status:\")\n",
        "for pkg, name in libraries:\n",
        "    version = get_version(pkg)\n",
        "    status = \"‚úÖ\" if \"not available\" not in version else \"‚ùå\"\n",
        "    print(f\"  {status} {name}: {version}\")\n",
        "\n",
        "print(\"\\nAll should show ‚úÖ - if you see ‚ùå, re-run installation above!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "006a2109",
      "metadata": {
        "id": "006a2109",
        "outputId": "aae7b32d-fd6f-4a7e-c54f-9ec0b8d3b59a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hardware Check:\n",
            "üñ•Ô∏è GPU: ‚ùå Not available (using CPU)\n",
            "   üí° No worries! CPU works fine for this course\n",
            "   üîß For GPU in Colab: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
            "\n",
            "üéâ Setup complete! Ready for your language adventure!\n"
          ]
        }
      ],
      "source": [
        "# üñ•Ô∏è Checking Checking available hardware\n",
        "#\n",
        "# This cell tests whether a GPU is accessible. The course can be completed on CPU,\n",
        "# but a GPU will make later experiments faster.\n",
        "\n",
        "print(\"\\nHardware Check:\")\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"üöÄ GPU: ‚úÖ {torch.cuda.get_device_name(0)} (CUDA {torch.version.cuda})\")\n",
        "        print(\"   üí° Great! You can run larger models faster\")\n",
        "    else:\n",
        "        print(\"üñ•Ô∏è GPU: ‚ùå Not available (using CPU)\")\n",
        "        print(\"   üí° No worries! CPU works fine for this course\")\n",
        "        print(\"   üîß For GPU in Colab: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Hardware check failed: {e}\")\n",
        "    print(\"üí° This might be okay - continue with the course\")\n",
        "\n",
        "print(\"\\nüéâ Setup complete! Ready for your language adventure!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ab568db",
      "metadata": {
        "id": "0ab568db"
      },
      "source": [
        "## üåç Step 3: Select your target language!\n",
        "\n",
        "Throughout the tutorial we will repeatedly use a small set of sentences in at least one target language. This session helps you define that set in a structured way.\n",
        "\n",
        "### üéØ Language Selection Strategy:\n",
        "```\n",
        "üèÜ Perfect Test Languages:\n",
        "‚îú‚îÄ‚îÄ üá±üá∫ Luxembourgish (~600K speakers)\n",
        "‚îú‚îÄ‚îÄ üáÆüá™ Irish (~1.7M speakers)  \n",
        "‚îú‚îÄ‚îÄ üá≤üáπ Maltese (~500K speakers)\n",
        "‚îú‚îÄ‚îÄ üáÆüá∏ Icelandic (~350K speakers)\n",
        "‚îú‚îÄ‚îÄ üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†Åø Welsh (~900K speakers)\n",
        "‚îî‚îÄ‚îÄ üá™üá∏ Basque (~750K speakers)\n",
        "```\n",
        "\n",
        "When choosing a language, consider.\n",
        "\n",
        "- coverage. languages with limited web presence are particularly interesting  \n",
        "- your own familiarity. you should be able to judge correctness and style  \n",
        "- script and morphology. non-Latin scripts or rich morphology often reveal weaknesses\n",
        "\n",
        "When creating sentences, aim for.\n",
        "\n",
        "- **Length**. roughly 6‚Äì20 words  \n",
        "- **Content**. a mix of simple statements, questions, numbers, borrowed words, and basic punctuation  \n",
        "- **Safety**. no personal names, addresses, or sensitive information\n",
        "\n",
        "The next cell defines a small dictionary with example sentences and allows you to add your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f30058e6",
      "metadata": {
        "id": "f30058e6",
        "outputId": "9aa7120a-b3d8-49dc-e514-03f9e46cb221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LANGUAGE SELECTED: lb\n",
            " Edit the line above to change your language\n",
            "\n",
            "\n",
            " Found example sentences for lb!\n",
            "\n",
            "üìã Your current dataset:\n",
            "üåç Language: lb\n",
            "üìä Number of sentences: 5\n",
            "üìù Example: 'Ech hunn Loscht ze verstoen, w√©i Sproochmodeller Text verschaffen.'\n",
            "\n",
            "üîç All your lb sentences:\n",
            "  1. Ech hunn Loscht ze verstoen, w√©i Sproochmodeller Text verschaffen.\n",
            "  2. D√´se Saz enth√§lt eng Zuel: 2026, an eng Komma.\n",
            "  3. Kuerz Prompte k√´nnen trotzdeem komplex √Ñntwerte produz√©ieren.\n",
            "  4. Tokenis√©ierung kann Bedeitung an K√§schte beaflossen.\n",
            "  5. Mir evalu√©ieren Richtegkeet, Fl√´ssegkeet an S√©cherheet.\n",
            "\n",
            "üí° Remember: You can edit these sentences anytime by modifying the cell above!\n"
          ]
        }
      ],
      "source": [
        "# üéØ Language dataset creation\n",
        "#\n",
        "# This cell defines your target language and a set of example sentences.\n",
        "# You should replace the example sentences with your own for the language you care about.\n",
        "\n",
        "# üåç Choose your target language (edit this line!)\n",
        "TARGET_LANG = \"lb\"  # üá±üá∫ Luxembourgish (change to your choice!)\n",
        "\n",
        "print(f\" LANGUAGE SELECTED: {TARGET_LANG}\")\n",
        "print(\" Edit the line above to change your language\")\n",
        "print()\n",
        "\n",
        "# üìö Your Test Sentences (REPLACE WITH YOUR OWN!)\n",
        "mini_texts = {\n",
        "    \"en\": [\n",
        "        \"I enjoy learning how language models process text.\",\n",
        "        \"This sentence includes a number: 2026, and a comma.\",\n",
        "        \"Short prompts can still produce complex outputs.\",\n",
        "        \"Tokenization choices can change meaning and cost.\",\n",
        "        \"We will evaluate correctness, fluency, and safety.\"\n",
        "    ],\n",
        "    \"lb\": [  # Luxembourgish examples\n",
        "        \"Ech hunn Loscht ze verstoen, w√©i Sproochmodeller Text verschaffen.\",\n",
        "        \"D√´se Saz enth√§lt eng Zuel: 2026, an eng Komma.\",\n",
        "        \"Kuerz Prompte k√´nnen trotzdeem komplex √Ñntwerte produz√©ieren.\",\n",
        "        \"Tokenis√©ierung kann Bedeitung an K√§schte beaflossen.\",\n",
        "        \"Mir evalu√©ieren Richtegkeet, Fl√´ssegkeet an S√©cherheet.\"\n",
        "    ],\n",
        "    \"ga\": [  # Irish examples\n",
        "        \"Is maith liom foghlaim conas a phr√≥ise√°lann samhlacha teanga t√©acs.\",\n",
        "        \"T√° uimhir sa abairt seo: 2026, agus cam√≥g.\",\n",
        "        \"Is f√©idir le leid ghearr aschuir chasta a th√°irgeadh f√≥s.\",\n",
        "        \"Is f√©idir le roghanna tocainithe br√≠ agus costas a athr√∫.\",\n",
        "        \"D√©anaimid meas√∫n√∫ ar chruinneas, l√≠ofacht agus s√°bh√°ilteacht.\"\n",
        "    ],\n",
        "    \"mt\": [  # Maltese examples\n",
        "        \"Jogƒßobni nitgƒßallem kif il-mudelli tal-lingwa jipproƒãessaw it-test.\",\n",
        "        \"Din is-sentenza tinkludi numru: 2026, u virgola.\",\n",
        "        \"Prompts qosra xorta jistgƒßu jipproduƒãu outputs kumplessi.\",\n",
        "        \"L-gƒßa≈ºliet tat-tokenization jistgƒßu jbiddlu t-tifsira u l-ispejje≈º.\",\n",
        "        \"Aƒßna nevalwaw it-tƒßassib, il-fluwenza u s-sigurt√†.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# üîß Add your language if it's not in the examples above\n",
        "if TARGET_LANG not in mini_texts:\n",
        "    print(f\"\\n {TARGET_LANG} not in examples - please add your sentences below!\")\n",
        "    mini_texts[TARGET_LANG] = [\n",
        "        \"Add your first sentence here (6-20 words).\",\n",
        "        \"Add your second sentence with a number: 2026.\",\n",
        "        \"Add your third sentence here.\",\n",
        "        \"Add your fourth sentence here.\",\n",
        "        \"Add your fifth sentence here.\"\n",
        "    ]\n",
        "    print(\" Edit the list above to add your own sentences!\")\n",
        "else:\n",
        "    print(f\"\\n Found example sentences for {TARGET_LANG}!\")\n",
        "\n",
        "print(f\"\\nüìã Your current dataset:\")\n",
        "print(f\"üåç Language: {TARGET_LANG}\")\n",
        "print(f\"üìä Number of sentences: {len(mini_texts[TARGET_LANG])}\")\n",
        "print(f\"üìù Example: '{mini_texts[TARGET_LANG][0]}'\")\n",
        "\n",
        "print(f\"\\nüîç All your {TARGET_LANG} sentences:\")\n",
        "for i, sentence in enumerate(mini_texts[TARGET_LANG], 1):\n",
        "    print(f\"  {i}. {sentence}\")\n",
        "\n",
        "print(\"\\nüí° Remember: You can edit these sentences anytime by modifying the cell above!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e21639",
      "metadata": {
        "id": "c4e21639"
      },
      "source": [
        "## üìä Step 4: Build a simple evaluation framework\n",
        "\n",
        "Time to create your secret weapon for systematic AI evaluation! For low-resource languages, standard automatic metrics are often unreliable or unavailable. To keep the analysis systematic across sessions, we will use a simple human-centric rating scheme.\n",
        "\n",
        "\n",
        "### For each model output, you will record.\n",
        "\n",
        "- **‚úÖ Correctness (0‚Äì2)**: Does the output solve the task or answer the question?\n",
        "- **üó£Ô∏è Fluency (0‚Äì2)**: Does the text read naturally in the target language?  \n",
        "- **üåç Cultural (0‚Äì2)**: Does the output respect linguistic and cultural norms?\n",
        "- **üõ°Ô∏è Safety (0‚Äì2)**: Does the output avoid harmful or inappropriate content?\n",
        "- **üìù Notes (0‚Äì2)**: Any additional observations about errors or interesting behaviour\n",
        "\n",
        "The next cell creates a table that combines English and your target language sentences. you will fill this table during later sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eefc27f9",
      "metadata": {
        "id": "eefc27f9"
      },
      "outputs": [],
      "source": [
        "# Building the evaluation sheet\n",
        "#\n",
        "# This creates a structured DataFrame with one row per input sentence.\n",
        "# You will fill in the model, prompt, ratings, and notes as you run experiments.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def create_evaluation_sheet(texts: dict, target_lang: str) -> pd.DataFrame:\n",
        "    \"\"\"Create evaluation sheet with empty columns to fill during sessions\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # Add both English and target language sentences\n",
        "    for lang in [\"en\", target_lang]:\n",
        "        if lang in texts:\n",
        "            for i, sentence in enumerate(texts[lang], 1):\n",
        "                rows.append({\n",
        "                    \"item_id\": f\"{lang}_{i}\",\n",
        "                    \"language\": lang,\n",
        "                    \"input_text\": sentence,\n",
        "                    \"task\": \"\",           # Session 1: summarization, Session 2: prompting, etc.\n",
        "                    \"model\": \"\",          # Which AI model was used\n",
        "                    \"prompt_style\": \"\",   # How you asked the AI\n",
        "                    \"output_text\": \"\",    # What the AI produced\n",
        "                    \"correctness_0to2\": \"\",  # 0=wrong, 1=mostly right, 2=perfect\n",
        "                    \"fluency_0to2\": \"\",      # 0=broken, 1=awkward, 2=natural\n",
        "                    \"cultural_0to2\": \"\",     # 0=inappropriate, 1=minor issues, 2=appropriate\n",
        "                    \"safety_0to2\": \"\",       # 0=harmful, 1=minor concerns, 2=safe\n",
        "                    \"notes\": \"\"              # Your observations\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Create your personal evaluation sheet\n",
        "eval_df = create_evaluation_sheet(mini_texts, TARGET_LANG)\n",
        "\n",
        "print(f\"üìã Created evaluation sheet: {len(eval_df)} rows\")\n",
        "print(f\"üåç Languages: English + {TARGET_LANG}\")\n",
        "print(f\"üìä Sentences per language: {len(mini_texts.get('en', []))}\")\n",
        "\n",
        "print(\"\\n Preview (you'll fill the empty columns during sessions):\")\n",
        "display(eval_df.head(6))\n",
        "\n",
        "#print(\"\\nüí° This will be your scientific log throughout all sessions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4510b9f2",
      "metadata": {
        "id": "4510b9f2"
      },
      "source": [
        "## üíæ Step 5: Save the evaluation sheet\n",
        "\n",
        "We now save the evaluation table to a CSV file so that you can.\n",
        "\n",
        "- re-use it in later sessions  \n",
        "- inspect or edit it outside the notebook if necessary  \n",
        "- keep a record of your ratings and model outputs\n",
        "\n",
        "The next cell writes the file to a folder called `session0_outputs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce3bbaa",
      "metadata": {
        "id": "5ce3bbaa"
      },
      "outputs": [],
      "source": [
        "# Saving the evaluation sheet to disk\n",
        "#\n",
        "# The file will be written as: session0_outputs/evaluation_sheet_<TARGET_LANG>.csv\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Create output folder and save evaluation sheet\n",
        "output_dir = Path(\"session0_outputs\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "filename = f\"evaluation_sheet_{TARGET_LANG}.csv\"\n",
        "file_path = output_dir / filename\n",
        "\n",
        "eval_df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"‚úÖ Saved: {filename}\")\n",
        "print(f\"üìÅ Location: {file_path}\")\n",
        "print(f\"üìä Contains: {len(eval_df)} rows for evaluation\")\n",
        "\n",
        "# Platform-specific download instructions\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print(\"\\nüì• In Colab: Files panel (left) ‚Üí session0_outputs ‚Üí right-click ‚Üí Download\")\n",
        "else:\n",
        "    print(f\"\\nüìÇ Local path: {os.path.abspath(file_path)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f40f0f",
      "metadata": {
        "id": "e4f40f0f"
      },
      "source": [
        "## ‚úÖ Step 6: Optional. test a multilingual model!\n",
        "\n",
        "If your network connection and runtime allow it, you can now perform a small sanity check.\n",
        "\n",
        "### üéØ This optional step will.:\n",
        "```\n",
        "ü§ñ Load a multilingual sentence embedding model\n",
        "üìä Encode your English and target language sentences  \n",
        "üìà Prepare data for a simple 2D visualization\n",
        "```\n",
        "\n",
        "**‚ö†Ô∏è Network issues? Skip this test and proceed - you're still ready for Session 1!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "592f294a",
      "metadata": {
        "id": "592f294a"
      },
      "outputs": [],
      "source": [
        "# ü§ñ Testing with a Real Multilingual AI Model\n",
        "#\n",
        "# This downloads and tests a multilingual model on your sentences.\n",
        "# It converts sentences to numbers (embeddings) that AI can compare.\n",
        "# This confirms your setup works and gives you a preview of Session 1!\n",
        "#\n",
        "# Note: First download takes 1-2 minutes (~420MB). Skip if network issues.\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "print(f\"üîÑ Loading multilingual model: {MODEL_NAME}\")\n",
        "print(\"‚è±Ô∏è First time: 1-2 minutes download (~420MB)\")\n",
        "\n",
        "try:\n",
        "    model = SentenceTransformer(MODEL_NAME)\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    # Prepare sentences from both languages\n",
        "    test_texts, test_labels = [], []\n",
        "    print(f\"\\nüìä Processing sentences:\")\n",
        "\n",
        "    for lang in [\"en\", TARGET_LANG]:\n",
        "        if lang in mini_texts:\n",
        "            for sentence in mini_texts[lang]:\n",
        "                test_texts.append(sentence)\n",
        "                test_labels.append(lang)\n",
        "                print(f\"  üìù {lang}: {sentence[:50]}{'...' if len(sentence) > 50 else ''}\")\n",
        "\n",
        "    # Convert sentences to numerical representations\n",
        "    print(f\"\\nüß† Converting {len(test_texts)} sentences to numbers...\")\n",
        "    embeddings = model.encode(test_texts, normalize_embeddings=True)\n",
        "\n",
        "    print(f\"‚úÖ Success! Each sentence ‚Üí {embeddings.shape[1]} numbers\")\n",
        "    print(f\"üìä Shape: {embeddings.shape} | üåç Languages: {len(set(test_labels))}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model loading failed: {e}\")\n",
        "    print(\"üí° Network issue? Skip this test - you can still continue!\")\n",
        "    print(\"üîß Or try: Runtime ‚Üí Restart Runtime, then re-run from top\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafbd8b0",
      "metadata": {
        "id": "dafbd8b0"
      },
      "source": [
        "### What PCA is doing in this plot\n",
        "\n",
        "The model turns each sentence into a vector of many numbers  \n",
        "For example 384 numbers for a single sentence  \n",
        "This is too many dimensions to show in a 2D plot  \n",
        "\n",
        "**Principal Component Analysis (PCA)** is a simple way to:\n",
        "\n",
        "- compress these high dimensional vectors into 2 numbers per sentence  \n",
        "- keep as much of the original variation as possible  \n",
        "\n",
        "You can think of it like this.\n",
        "\n",
        "- Imagine you have a 3D object, but you can only draw on a flat sheet of paper  \n",
        "- You shine a light and look at the shadow on the paper  \n",
        "- The shadow loses some detail, but you still see the main shape  \n",
        "\n",
        "Here.\n",
        "\n",
        "- the 3D object is actually a high dimensional sentence embedding  \n",
        "- the 2D shadow is the point we plot for that sentence  \n",
        "\n",
        "In the scatter plot below.\n",
        "\n",
        "- each point is one sentence  \n",
        "- points that are close together represent sentences that the model sees as similar  \n",
        "- you can check whether sentences from different languages stay separate or mix together in this 2D space  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c219b14a",
      "metadata": {
        "id": "c219b14a"
      },
      "outputs": [],
      "source": [
        "# üìà Visualizing How AI \"Sees\" Your Languages\n",
        "#\n",
        "# This creates a 2D map showing how the AI model groups your sentences.\n",
        "# Sentences with similar meanings should appear close together.\n",
        "# This gives you insight into how well the model understands your language!\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'embeddings' in locals():\n",
        "    print(\" Creating language visualization...\")\n",
        "\n",
        "    # Reduce high-dimensional numbers to 2D for plotting\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    embeddings_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "    # Create the visualization\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    for i, lang in enumerate(sorted(set(test_labels))):\n",
        "        # Plot sentences from each language in different colors\n",
        "        lang_indices = [j for j, label in enumerate(test_labels) if label == lang]\n",
        "        plt.scatter(embeddings_2d[lang_indices, 0], embeddings_2d[lang_indices, 1],\n",
        "                   label=f'{lang} ({len(lang_indices)} sentences)',\n",
        "                   color=colors[i % len(colors)], s=100, alpha=0.7)\n",
        "\n",
        "    plt.title(f'üåç How AI \"Sees\" Your Languages\\n(Each dot = one sentence)', fontsize=14)\n",
        "    plt.xlabel('üìä Dimension 1', fontsize=12)\n",
        "    plt.ylabel('üìä Dimension 2', fontsize=12)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.figtext(0.5, 0.02, 'üí° Closer dots = more similar meanings to the AI',\n",
        "                ha='center', fontsize=10, style='italic')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"üéâ Visualization complete!\")\n",
        "    print(\"üîç Questions you can ask yourself.\")\n",
        "    print(\"  ‚Ä¢ Do sentences from the same language cluster together?\")\n",
        "    print(\"  ‚Ä¢ Do semantically similar sentences appear in similar regions?\")\n",
        "    print(\"  ‚Ä¢ Any surprising patterns?\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Skipping visualization - model loading failed above\")\n",
        "    print(\"üí° This is okay - you can still continue with the course!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2f8981",
      "metadata": {
        "id": "6f2f8981"
      },
      "source": [
        "## üÜò Troubleshooting\n",
        "\n",
        "**üîß Some common issues and suggested actions:**\n",
        "- **Installation errors:**\n",
        "  - Restart the runtime and re-run the installation cell  \n",
        "  - Check that you are using a recent Python version\n",
        "- **Model download failures:**\n",
        "  - Often caused by transient network problems  \n",
        "  - Try again later or skip the optional model test\n",
        "- **Out of memory errors:**\n",
        "  - Switch to a smaller model or use CPU only  \n",
        "  - In Colab, verify that you have not opened multiple notebooks in the same session\n",
        "- **Encoding or Unicode problems:**\n",
        "  - Ensure files are saved with UTF-8 encoding  \n",
        "  - Avoid mixing encodings in the same project\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dee37ce",
      "metadata": {
        "id": "9dee37ce"
      },
      "source": [
        "## üéØ Mission Complete! What's Next?\n",
        "\n",
        "### ‚úÖ Before you move to Session 1:\n",
        "It is useful to confirm that you have.\n",
        "- [ ] At least one target language selected  \n",
        "- [ ] A set of 5‚Äì10 sentences in that language, saved in this notebook  \n",
        "- [ ] An evaluation sheet CSV file saved under `session0_outputs/`  \n",
        "- [ ] A rough idea of what might be challenging for your language  \n",
        "      (for example. morphology, spelling variation, code-switching)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bf43678",
      "metadata": {
        "id": "9bf43678"
      },
      "source": [
        "### ü§î Reflection and next steps\n",
        "\n",
        "You can note down short answers to the following questions.\n",
        "\n",
        "1. Which phenomena in your language do you expect LLMs to handle poorly.  \n",
        "2. Where do you anticipate prompt following to break down first.  \n",
        "3. What would count as a successful outcome for you at the end of the tutorial.\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully completed Session 0!\n",
        "\n",
        "**üöÄ Ready for Session 1?** Open `Session1_Dialogue_Summarization_Low_Resource.ipynb` and let the adventure continue!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}